<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>This Is Fine</title>
    <link>https://shuaib.me/</link>
    <description>Recent content on This Is Fine</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Oct 2019 00:11:25 +0100</lastBuildDate>
    <atom:link href="https://shuaib.me/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Learning to Rank Places for Geospatial Search</title>
      <link>https://shuaib.me/learning-to-rank-places/</link>
      <pubDate>Fri, 04 Oct 2019 00:11:25 +0100</pubDate>
      
      <guid>https://shuaib.me/learning-to-rank-places/</guid>
      <description>&lt;p&gt;I recently completed a master&amp;rsquo;s degree in data science at the Beuth University of Applied Sciences. As part of the study program, I authored a thesis titled Learning to Rank Places. Here are links to the &lt;a href=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/files/Thesis.pdf&#34;&gt;thesis&lt;/a&gt; and &lt;a href=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/files/Learning_to_Rank_Places_Slides.pdf&#34;&gt;presentation slides&lt;/a&gt; for the defence. Also, you can read the abstract below.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Ranking problems are omnipresent in interactions with software that retrieve information. Advancements in machine learning (ML) have led to novel solutions for solving ranking problems using a set of approaches known as Learning to Rank (LTR). The goal of this thesis is to demonstrate the effectiveness of learning to rank in solving the problem of ranking geographic places intended for navigation by comparing it to an existing place search engine called Pelias. Clickthrough logs collected from Pelias usage were utilized to create a training dataset for the learning to rank models. Linear, tree-based, and neural learning to rank models were built using the standard ML workflow and evaluated offline using the Mean Reciprocal Rank (MRR) metric. The tree-based models show significant MRR improvements over Pelias, while a subset of the linear and neural models show marginal improvements. An analysis of the results revealed open questions and clear directions for future work on the LTR models.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing Streets Clustered by Address Layout</title>
      <link>https://shuaib.me/ars-cluster-viz/</link>
      <pubDate>Wed, 01 May 2019 00:09:45 +0100</pubDate>
      
      <guid>https://shuaib.me/ars-cluster-viz/</guid>
      <description>&lt;p&gt;This post is a continuation of &lt;a href=&#34;https://shuaib.me/clustering-ars/&#34;&gt;Clustering Address Reference Systems&lt;/a&gt;. After running a clustering algorithm, it&amp;rsquo;s always good to have a way of visually inspecting the clusters produced. I wanted to have an interactive plot of streets colored by their clusters assignments; where I could click on a street and its name would be displayed. You can find the notebook containing the cluster visualization code &lt;a href=&#34;https://github.com/shuaibiyy/address-interpolation/blob/master/VisualizeStreetARS.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Essentially, we want to plot streets with colors within any axis of our choice. There are 4 main steps to getting what we want:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Get the axis of a bounding box.&lt;/li&gt;
&lt;li&gt;Get the names of streets within that bounding box.&lt;/li&gt;
&lt;li&gt;Get the polylines for those streets.&lt;/li&gt;
&lt;li&gt;Plot the polylines color-coded by their cluster assignments.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Before any of the steps listed above though, we need to load the data frame containing the cluster assignments generated by K-Means algorithm in the &lt;a href=&#34;https://shuaib.me/clustering-ars/&#34;&gt;previous post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Get the axis of a bounding box.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To accomplish this, we use &lt;a href=&#34;https://github.com/gboeing/osmnx&#34;&gt;OSMnx&lt;/a&gt;. OSMnx is a really neat python library for visualizing streets from Openstreetmap. It is easy to use, and all it takes is 2 lines to plot a street:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;G = ox.graph_from_address(&#39;Prenzlauer Berg, Berlin, Germany&#39;, distance=1000)
fig, ax = ox.plot_graph(G, fig_height=10, fig_width=10, show=False, close=False, edge_color=&#39;#D3D3D3&#39;, node_edgecolor=&#39;#D3D3D3&#39;, node_size=25, node_zorder=3, node_color=&#39;w&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The polylines in step 4 below will be plotted over the axis of our OSMnx plot. This adds a nice touch of showing OSMnx network nodes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Get the names of the streets streets within that bounding box.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To do this, we make a request to the &lt;a href=&#34;https://overpass-turbo.eu/&#34;&gt;Overpass API&lt;/a&gt;. The Overpass API allows you to query OSM data. Using Overpass turned out to be rather straightforward:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def fetch_streets_within_bbox(min_lat, min_lon, max_lat, max_lon):
  overpass_url = &amp;quot;http://overpass-api.de/api/interpreter&amp;quot;
  overpass_query = f&amp;quot;&amp;quot;&amp;quot;
  [out:json];
  (
   way({min_lat},{min_lon},{max_lat},{max_lon})[highway][name];
  );
  out center;
  &amp;quot;&amp;quot;&amp;quot;
  response = requests.get(overpass_url,
                          params={&#39;data&#39;: overpass_query})
  return response.json()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3. Get the polylines for those streets.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For that, we can use the &lt;a href=&#34;https://github.com/pelias/polylines#download-data&#34;&gt;polyline files&lt;/a&gt; generated by the good folks from Pelias. &lt;a href=&#34;https://developers.google.com/maps/documentation/utilities/polylinealgorithm&#34;&gt;According to the creators of the polyline format&lt;/a&gt;, &amp;ldquo;Polyline encoding is a lossy compression algorithm that allows you to store a series of coordinates as a single string&amp;rdquo;. We download the polyline file for Berlin streets and parse it using this function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_polylines():
  with open(&#39;./data/berlin.polylines&#39;, &#39;r&#39;) as f:
    polylines = {}
    lines = f.read().splitlines()
    for l in lines:
      val, key = l.split(&#39;\0&#39;)
      existing_line = polylines[key] if key in polylines else []
      existing_line.append(val)
      polylines[key] = existing_line

    return polylines
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;4. Plot the polylines colored by their cluster assignments.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Using the axis from step 1, we iterate through all the street polylines; plot them on the axis; and color them based on their cluster assignments.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%matplotlib notebook

text_x, _ = ax.get_xlim()
text_y, _ = ax.get_ylim()

text = ax.text(text_x, text_y, &#39;&#39;, va=&#39;bottom&#39;, weight=&#39;bold&#39;)

plot_streets_within_axis(ax)

def on_plot_hover(event):
    for curve in ax.get_lines():
        if curve.contains(event)[0]:
            text.set_text(curve.get_gid())
            break

fig.canvas.mpl_connect(&#39;button_press_event&#39;, on_plot_hover)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make the plot interactive, we specify the &lt;em&gt;%matplotlib notebook&lt;/em&gt; magic command. The interactivity we want is to be able to click on any street in the plot and have its name displayed in the bottom left corner of the plot. It took me a while and the aid of some Stack Overflow answers to figure out this whole interactivity thing. At the end, we have an interactive plot that looks like this:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ars-viz/Prenzlauer.png&#34; alt=&#34;Streets in Prenzlauer Berg, Berlin Color-Coded by Address Layout&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Streets in Prenzlauer Berg, Berlin Color-Coded by Address Layout
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;You can try out the &lt;a href=&#34;https://github.com/shuaibiyy/address-interpolation/blob/master/VisualizeStreetARS.ipynb&#34;&gt;notebook&lt;/a&gt; yourself.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Clustering Address Reference Systems</title>
      <link>https://shuaib.me/clustering-ars/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:23 +0100</pubDate>
      
      <guid>https://shuaib.me/clustering-ars/</guid>
      <description>&lt;p&gt;&lt;em&gt;You can have a look at this &lt;a href=&#34;https://github.com/shuaibiyy/address-interpolation/blob/master/Preparation.ipynb&#34;&gt;Jupyter notebook&lt;/a&gt; for the data preparation, and &lt;a href=&#34;https://github.com/shuaibiyy/address-interpolation/blob/master/ARS.ipynb&#34;&gt;this one&lt;/a&gt; for the setup and implementation of the Address Reference System clustering.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Say you&amp;rsquo;re building search functionality similar to Google Maps search and you want your users to be able to search for addresses. A key part of delivering this would be collecting address data. Luckily, there are data sources like &lt;a href=&#34;https://openaddresses.io/&#34;&gt;Openaddresses&lt;/a&gt; and &lt;a href=&#34;https://www.openstreetmap.org/&#34;&gt;Openstreetmap&lt;/a&gt; that provide free access to such data. However, these data sources suffer from a problem of missing house addresses. Address data can be incomplete due to data recording errors, destruction or construction of buildings, or a myriad of other reasons. One way to handle missing addresses is to predict the coordinates of an address based on data about other addresses on the same street. Say you have the coordinates for &lt;em&gt;Main Street 1, 2, 3, &amp;amp; 5&lt;/em&gt;; you could approximate the coordinates for &lt;em&gt;Main Street 4&lt;/em&gt;. This is feasible because houses on a street tend to be laid out in some sequence, and the structure of that sequence is part of what is known as an &lt;strong&gt;Address Reference System (ARS)&lt;/strong&gt;. In an ideal world, a city or municipality would have a standard ARS that&amp;rsquo;s used for every street. In reality, that&amp;rsquo;s often not the case.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ars/Arendsweg.png&#34; alt=&#34;Arendsweg 13055, Berlin&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Addresses on a street follow some sequence and layout. For example, even numbered houses on one side of the road, and odd numbered houses on the other side, starting from the least number in the range to the highest. We can denote addresses on the right and left side of streets as &lt;em&gt;R&lt;/em&gt; and &lt;em&gt;L&lt;/em&gt; respectively, then a street can be described by a sequence such as &lt;em&gt;RRRLLL&lt;/em&gt;, or &lt;em&gt;RLRLRLRL&lt;/em&gt; etc. The street in the image above has its addresses in this sequence: &lt;em&gt;LLLLLLLLRLRLLLLLRRLRLRLLRRLLLLLLLLR&lt;/em&gt;; odd numbered houses are on the left side of the street and the even numbered on the right side.&lt;/p&gt;

&lt;p&gt;To improve the accuracy of address interpolation, we&amp;rsquo;d need to know the side of the street a house lies on; in other words, we need to know the ARS or layout of streets in a area. The approach I took was to apply the K-Means clustering algorithm to street parity sequences. The term parity refers the side of the road where an address is located i.e. left (&lt;em&gt;L&lt;/em&gt;) or right (&lt;em&gt;R&lt;/em&gt;). To extract address parities from streets, I used the &lt;a href=&#34;https://github.com/pelias/interpolation&#34;&gt;Pelias interpolation&lt;/a&gt; tool. You can have a look at the &lt;a href=&#34;https://github.com/shuaibiyy/address-interpolation/blob/master/Preparation.ipynb&#34;&gt;data preparation notebook&lt;/a&gt; for more details.&lt;/p&gt;

&lt;p&gt;In order to apply the K-Means algorithm on street sequences, a little feature engineering is required. In this case that involves using scikit-learn&amp;rsquo;s &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html&#34;&gt;CountVectorizer&lt;/a&gt; on ngrams of length 5 for each street sequence parity. Keep in mind that the training data for this exercise is restricted to Berlin.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ars/CountVectorizer.png&#34; alt=&#34;CountVectorizer&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Afterwards, we pass the vectors and value of &lt;em&gt;K&lt;/em&gt; into the &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html&#34;&gt;K-Means algorithm&lt;/a&gt;, and get back cluster assignments for each street.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ars/KMeans.png&#34; alt=&#34;K-Means&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Next, we can inspect the cluster assignments to see how well our algorithm did. Since we ran the K-Means with &lt;em&gt;K=2&lt;/em&gt;, we expect that the algorithm learned 2 distinct types of street layouts. Let&amp;rsquo;s inspect a couple of streets in &lt;strong&gt;cluster 1&lt;/strong&gt;:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ars/Winsstra%c3%9fe.png&#34; alt=&#34;Winsstraße, Prenzlauer Berg, Berlin, Germany&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Winsstraße, Prenzlauer Berg, Berlin, Germany
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;figure &gt;
    
        &lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ars/Papelallee.png&#34; alt=&#34;Pappelallee, Prenzlauer Berg, Berlin, Germany&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Pappelallee, Prenzlauer Berg, Berlin, Germany
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;And a couple of streets in &lt;strong&gt;cluster 2&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ars/John-Schehr-Stra%c3%9fe.png&#34; alt=&#34;John-Schehr-Straße, Prenzlauer Berg, Berlin, Germany&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        John-Schehr-Straße, Prenzlauer Berg, Berlin, Germany
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ars/Hufelandstra%c3%9fe.png&#34; alt=&#34;Hufelandstraße, Prenzlauer Berg, Berlin, Germany&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Hufelandstraße, Prenzlauer Berg, Berlin, Germany
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What can we understand from the cluster assignments?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Cluster 1 shows us streets with addresses in a &lt;strong&gt;horseshoe&lt;/strong&gt; layout. The addresses run in sequence on one side of the street and wrap around to the other side.&lt;/p&gt;

&lt;p&gt;Cluster 2 shows us streets with addresses in an &lt;strong&gt;even-odd&lt;/strong&gt; layout. Even-numbered addresses are on one side of the street, while odd-numbered ones are on the other side.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning about Adversarial Perturbations</title>
      <link>https://shuaib.me/adversarial-perturbations/</link>
      <pubDate>Sat, 01 Dec 2018 00:12:23 +0100</pubDate>
      
      <guid>https://shuaib.me/adversarial-perturbations/</guid>
      <description>&lt;p&gt;Adversarial perturbations are special kinds of distortions that trick machine learning and deep learning models into misclassifying their input. Adversarial examples in neural networks were first discovered and explored by Szegedy et al. (2013) in their paper: &lt;a href=&#34;https://arxiv.org/abs/1312.6199&#34;&gt;Intriguing properties of neural networks&lt;/a&gt;. They showed that distortions or perturbations can be learnt from a model, which when applied to its input, cause the model to confidently misclassify the input.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ostrich.jpeg&#34; alt=&#34;Take a correctly classified image (left image in both columns), and add a tiny distortion (middle) to fool the ConvNet with the resulting image (right). Taken from http://karpathy.github.io/2015/03/30/breaking-convnets/.&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Take a correctly classified image (left image in both columns), and add a tiny distortion (middle) to fool the ConvNet with the resulting image (right). Taken from http://karpathy.github.io/2015/03/30/breaking-convnets/.
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Adversarial examples are input that have been perturbed. Adversarial training is a technique for improving the defense of a deep learning model against adversarial perturbations by incorporating adversarial examples during model training.&lt;/p&gt;

&lt;p&gt;Recently, as part of my academic coursework, I chose to review a paper titled: &lt;a href=&#34;https://arxiv.org/abs/1511.04599&#34;&gt;DeepFool: a simple and accurate method to fool deep neural networks&lt;/a&gt;. The crux of the paper is the introduction of an algorithm called DeepFool that is effective at finding the minimal perturbations necessary to fool DNNs. Furthermore, the perturbations that are learnt using DeepFool are more effective for adversarial training compared to a pre-existing method called Fast Gradient Sign Method (FGSM). In order to get up to speed with adversarial learning, I found these sources especially helpful:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ml.berkeley.edu/blog/2018/01/10/adversarial-examples/&#34;&gt;Tricking Neural Networks: Create your own Adversarial Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=CIfsB_EYsVI&#34;&gt;Lecture 16 | Adversarial Examples and Adversarial Training
By Ian Goodfellow&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://karpathy.github.io/2015/03/30/breaking-convnets/&#34;&gt;Breaking Linear Classifiers on ImageNet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1312.6199&#34;&gt;Intriguing properties of neural networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1412.6572&#34;&gt;Explaining and Harnessing Adversarial Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1610.08401&#34;&gt;Universal adversarial perturbations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1707.04131&#34;&gt;Foolbox: A Python toolbox to benchmark the robustness of machine learning models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Threading a DB Connection through a Go API Server</title>
      <link>https://shuaib.me/thread-db-conn-go-server/</link>
      <pubDate>Sat, 14 Jan 2017 02:42:18 +0100</pubDate>
      
      <guid>https://shuaib.me/thread-db-conn-go-server/</guid>
      <description>&lt;p&gt;In this post, I&amp;rsquo;ll walk through code snippets for a Golang service, showing how a database connection can be passed around from its initialisation all the way to HTTP handlers. There&amp;rsquo;s also a snippet that shows how a custom handler type can be used as a &lt;a href=&#34;https://github.com/urfave/negroni&#34;&gt;Negroni&lt;/a&gt; middleware. The service exposes 3 endpoints. It uses the &lt;a href=&#34;https://github.com/jackc/pgx&#34;&gt;pgx&lt;/a&gt; library for persistence, &lt;a href=&#34;http://www.gorillatoolkit.org/pkg/mux&#34;&gt;gorilla/mux&lt;/a&gt; for routing, Negroni for HTTP middleware, and &lt;a href=&#34;https://auth0.com/&#34;&gt;Auth0&lt;/a&gt; for authentication.&lt;/p&gt;

&lt;p&gt;This first snippet shows some very standard code for database initialisation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
	&amp;quot;fmt&amp;quot;
	_ &amp;quot;github.com/jackc/pgx/stdlib&amp;quot;
	&amp;quot;github.com/jmoiron/sqlx&amp;quot;
	&amp;quot;log&amp;quot;
	&amp;quot;os&amp;quot;
)

func Init() *sqlx.DB {
	db, err := sqlx.Open(&amp;quot;pgx&amp;quot;,
		fmt.Sprintf(&amp;quot;postgres://%s@%s:5432/postgres?sslmode=disable&amp;quot;,
			os.Getenv(&amp;quot;DB_USER&amp;quot;),
			os.Getenv(&amp;quot;DB_SERVER&amp;quot;)))
	if err != nil {
		log.Fatal(err)
	}
	if err := db.Ping(); err != nil {
		log.Fatal(err)
	}
	return db
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next snippet shows how the service&amp;rsquo;s routes are defined.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Route struct {
	Name    string
	Method  string
	Pattern string
	Handler HandlerWithDB // [1]
}

type Routes []Route
var routes = Routes{
	Route{
		&amp;quot;IndexTags&amp;quot;,
		&amp;quot;GET&amp;quot;,
		&amp;quot;/tags&amp;quot;,
		handlers.IndexTags,
	},
	Route{
		&amp;quot;ShowTag&amp;quot;,
		&amp;quot;GET&amp;quot;,
		&amp;quot;/tags/{slug}&amp;quot;,
		handlers.ShowTag,
	},
	Route{
		&amp;quot;SecuredCreateTag&amp;quot;, // [2]
		&amp;quot;POST&amp;quot;,
		&amp;quot;/tags&amp;quot;,
		handlers.CreateTag,
	},
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[1] This is the type of the API&amp;rsquo;s handlers, and is defined as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type HandlerWithDB func(*sqlx.DB) http.HandlerFunc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which means our API handlers end up looking like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var ShowTag = func(dbConn *sqlx.DB) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		slug := mux.Vars(r)[&amp;quot;slug&amp;quot;]
		tag, err := db.SelectTag(dbConn, slug)
		if err != nil {
			http.Error(w, err.Error(), http.StatusNotFound)
			return
		}
		json.NewEncoder(w).Encode(tag)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[2] The &lt;strong&gt;SecuredCreateTag&lt;/strong&gt; endpoint will require user authentication. The presence of the &lt;strong&gt;Secure&lt;/strong&gt; prefix in the handler&amp;rsquo;s name will let the router creation function know that the handler should be wrapped by a higher-order function that enforces authentication.&lt;/p&gt;

&lt;p&gt;The next snippet shows how the routers defined above are used to create a &lt;a href=&#34;www.gorillatoolkit.org/pkg/mux&#34;&gt;mux&lt;/a&gt; router:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
	&amp;quot;github.com/gorilla/mux&amp;quot;
	&amp;quot;github.com/jmoiron/sqlx&amp;quot;
	&amp;quot;github.com/urfave/negroni&amp;quot;
	&amp;quot;strings&amp;quot;
	&amp;quot;net/http&amp;quot;
)

func NewRouter(db *sqlx.DB) *mux.Router {
	r := mux.NewRouter().StrictSlash(true)
	for _, route := range routes {
		n := strings.ToLower(route.Name)
		if strings.HasPrefix(n, &amp;quot;secure&amp;quot;) { // [3]
			r.Handle(route.Pattern, auth.SecuredRoute(db, route.Handler)).Methods(route.Method).Name(route.Name)
		} else {
			r.Handle(route.Pattern, route.Handler(db)).Methods(route.Method).Name(route.Name)
		}
	}
	return r
}


// [4]
var SecuredRoute = func(db *sqlx.DB, handler HandlerWithDB) http.Handler {
	return negroni.New(negroni.HandlerFunc(jwtMiddleware.HandlerWithNext), NegroniWrapper(db, handler)) // [5]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[3] Of note is the check for the word &lt;strong&gt;secure&lt;/strong&gt; in the handler&amp;rsquo;s name. The use of a string to determine if an endpoint should be secured is at best an arguable thing to do. However, for my  inconsequential service, I can still sleep peacefully at night knowing fully well what I&amp;rsquo;ve done.&lt;/p&gt;

&lt;p&gt;[4] The &lt;strong&gt;SecuredRoute&lt;/strong&gt; function uses &lt;a href=&#34;https://github.com/urfave/negroni&#34;&gt;Negroni&lt;/a&gt; to wrap &lt;strong&gt;jwtmiddleware&lt;/strong&gt; from &lt;a href=&#34;https://github.com/auth0/go-jwt-middleware&#34;&gt;Go JWT middleware&lt;/a&gt; by Auth0. Auth0 is an awesome service for offloading all of your authentication concerns &amp;lt;3&lt;/p&gt;

&lt;p&gt;[5] The &lt;strong&gt;New&lt;/strong&gt; function from Negroni creates a middleware stack that can consist only of Negroni handlers, and we are passing it a &lt;strong&gt;HandlerWithDB&lt;/strong&gt; function, which is our type that does not implement the Negroni &lt;strong&gt;Handler&lt;/strong&gt; interface. Negroni provides a &lt;strong&gt;Wrap&lt;/strong&gt; function, but it is only able to wrap &lt;strong&gt;http.Handler&lt;/strong&gt; functions. In order to use Negroni, we have to write a wrapper for &lt;strong&gt;HandlerWithDB&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
	&amp;quot;github.com/jmoiron/sqlx&amp;quot;
	&amp;quot;github.com/urfave/negroni&amp;quot;
	&amp;quot;net/http&amp;quot;
)

type HandlerWithDB func(*sqlx.DB) http.HandlerFunc

// [6]
func (f HandlerWithDB) ServeHTTP(db *sqlx.DB, w http.ResponseWriter, r *http.Request) {
	g := f(db)
	g(w, r)
}

func NegroniWrapper(db *sqlx.DB, handler HandlerWithDB) negroni.Handler {
	return negroni.HandlerFunc(func(rw http.ResponseWriter, r *http.Request, next http.HandlerFunc) {
		handler.ServeHTTP(db, rw, r)
		next(rw, r)
	})
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[6] We also have to define a &lt;strong&gt;ServeHTTP&lt;/strong&gt; function that takes a database connection as an additional argument.&lt;/p&gt;

&lt;p&gt;Finally, our main function to tie it all together:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import (
	&amp;quot;net/http&amp;quot;
	&amp;quot;os&amp;quot;
)

func main() {
	dbConn := db.Init()
	router := NewRouter(dbConn)
	log.Fatal(http.ListenAndServe(&amp;quot;:8080&amp;quot;, router))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is my first Go service. I hope you&amp;rsquo;ll be generous enough to give feedback if you have any.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Passing Key-value Program Arguments to Go Programs in Code</title>
      <link>https://shuaib.me/passing-key-val-prog-args-in-code/</link>
      <pubDate>Wed, 25 May 2016 21:16:07 +0800</pubDate>
      
      <guid>https://shuaib.me/passing-key-val-prog-args-in-code/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m currently working on &lt;a href=&#34;https://github.com/shuaibiyy/topo&#34;&gt;Topo&lt;/a&gt;, a tool that aids provisioning multiple &lt;a href=&#34;https://terraform.io&#34;&gt;Terraform&lt;/a&gt; configurations of the same project. An example use-case where Topo might be a good solution is: say you want to provision multiple Jenkins servers for different teams, and you want to maintain the state of the resources so you can run Terraform to reapply as the configuration or capacity changes, or destroy.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m writing Topo in &lt;a href=&#34;https://golang.org/&#34;&gt;Go&lt;/a&gt;, and I&amp;rsquo;m using the &lt;a href=&#34;https://github.com/codeskyblue/go-sh&#34;&gt;go-sh&lt;/a&gt; package to programmatically run shell processes. All was going well till I had to write the &lt;a href=&#34;https://www.terraform.io/docs/commands/remote-config.html&#34;&gt;Terraform remote config command&lt;/a&gt; for configuring remote state storage in S3. The command looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;terraform remote config \
    -backend=s3 \
    -backend-config=&amp;quot;bucket=terraform-state-prod&amp;quot; \
    -backend-config=&amp;quot;key=network/terraform.tfstate&amp;quot; \
    -backend-config=&amp;quot;region=us-east-1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In my code, I wrote the go-sh command like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;sh.Command(&amp;quot;terraform&amp;quot;, &amp;quot;remote&amp;quot;, &amp;quot;config&amp;quot;,
	&amp;quot;-backend=s3&amp;quot;, &amp;quot;-backend-config=&#39;bucket=jenkins-bucket&#39;&amp;quot;,
	&amp;quot;-backend-config=&#39;key=jenkins/terraform.tfstate&#39;&amp;quot;,
	sh.Dir(&amp;quot;projects/jenkins&amp;quot;)).Run()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That doesn&amp;rsquo;t work though, and results in this error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;missing &#39;bucket&#39; configuration

If the error message above mentions requiring or modifying configuration
options, these are set using the `-backend-config` flag. Example:
-backend-config=&amp;quot;name=foo&amp;quot; to set the `name` configuration
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The Terraform command works perfectly when run the command line. I spent a couple of hours trying stuff out. Terraform is a &lt;a href=&#34;https://golang.org/&#34;&gt;Go&lt;/a&gt; program, and it turns out that Go programs accept flags as key-value pairs(except for booleans) separated by equals sign (&amp;ldquo;=&amp;rdquo;). Breaking up the arguments like below from &amp;ldquo;key=&amp;lsquo;value&amp;rsquo;&amp;rdquo; to &amp;ldquo;key&amp;rdquo;, &amp;ldquo;value&amp;rdquo; solves the problem:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;sh.Command(&amp;quot;terraform&amp;quot;, &amp;quot;remote&amp;quot;, &amp;quot;config&amp;quot;, &amp;quot;-backend=s3&amp;quot;,
    &amp;quot;-backend-config&amp;quot;, &amp;quot;bucket=jenkins-bucket&amp;quot;,
    &amp;quot;-backend-config&amp;quot;, &amp;quot;key=jenkins/terraform.tfstate&amp;quot;,
    sh.Dir(&amp;quot;projects/jenkins&amp;quot;)).Run()
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ECS-Powered Jenkins</title>
      <link>https://shuaib.me/ecs-jenkins/</link>
      <pubDate>Fri, 13 May 2016 03:33:00 +0800</pubDate>
      
      <guid>https://shuaib.me/ecs-jenkins/</guid>
      <description>&lt;p&gt;I was recently in search of a scalable and cost-effective Jenkins setup using docker containers. I found what I believe satisfies that requirement by running Jenkins on &lt;a href=&#34;https://aws.amazon.com/ecs/&#34;&gt;Amazon EC2 Container Service (ECS)&lt;/a&gt;. The simplest form of the setup involves running a single Jenkins master in an ECS cluster. To run builds in slaves, I use the &lt;a href=&#34;https://wiki.jenkinsci.org/display/JENKINS/Amazon+EC2+Container+Service+Plugin&#34;&gt;Amazon ECS Jenkins plugin&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The way it works is, you add an ECS cluster as what is called a &amp;ldquo;Cloud&amp;rdquo; in the &amp;ldquo;Manage Jenkins&amp;rdquo; section of Jenkins configuration, and an &amp;ldquo;ECS slave template&amp;rdquo; that describes a docker image and its resource constraints. When you define your job configuration, you have to specify a restriction for where the job can run that matches a label you provided while declaring a slave template. The setup steps are well documented in the ECS plugin page.&lt;/p&gt;

&lt;p&gt;I created a Terraform module that automates provisioning Jenkins on ECS using Terraform, it also provides a Terraform script for building and releasing your custom Jenkins image to &lt;a href=&#34;https://aws.amazon.com/ecr/&#34;&gt;Amazon EC2 Container Registry (ECR)&lt;/a&gt;. You can find the Github repo &lt;a href=&#34;https://github.com/shuaibiyy/ecs-jenkins&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;With everything set up - when builds are run, the ECS plugin starts an ECS task running a docker container from a configured slave template docker image and runs the build on it. ECS tasks are ephemeral, so once the build completes or fails, the task gets cleaned up. Here&amp;rsquo;s an illustration of how everything ties up together:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://rawgit.com/shuaibiyy/shuaib.me/master/themes/hugo-cactus-theme/images/ecs-jenkins.png&#34; alt=&#34;ECS Jenkins&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In conclusion, I find that this is a superior approach over spot instances because builds are unlikely to be terminated abruptly and better than long running Jenkins slaves because of their upfront resource commitment. I am yet to see how this works with autoscaling though, as I imagine that if the provisioned EC2 instances don&amp;rsquo;t have the capacity to serve the requested builds, new instances should be spawned up based on the autoscaling policy.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HAProxy Configuration Management with Lambda-Registry and Cosmonaut</title>
      <link>https://shuaib.me/haproxy-config-mgmt-lambda-registry-cosmonaut/</link>
      <pubDate>Sun, 08 May 2016 02:18:18 +0800</pubDate>
      
      <guid>https://shuaib.me/haproxy-config-mgmt-lambda-registry-cosmonaut/</guid>
      <description>

&lt;h2 id=&#34;background:590f6df10d6bcf152493e39f0a6f759c&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;Deployment solutions for all sorts of application architectures are pretty common and well-known these days. A month ago, I set out to find tooling that could handle deploying a couple hundred single-tenanted applications in containers, and I found some, but nothing simple enough for the bus factor I had in mind. I wanted to leverage existing simple tools without buying into configuration heavy machinery. I finally settled on a set of tools that work well, but I had to build what I found to be missing pieces. The set of tools consists of the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/documentation/ecs/&#34;&gt;Amazon ECS&lt;/a&gt; for orchestration and scheduling.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.docker.com/what-docker&#34;&gt;Docker&lt;/a&gt; mainly because of ECS.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.haproxy.org/&#34;&gt;HAProxy&lt;/a&gt; for load balancing and URL routing.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.weave.works/products/weave-net/&#34;&gt;Weave NET&lt;/a&gt; to provide an overlay network for Docker; bridging together multiple hosts and allowing containers to find each other.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt; for provisioning the entire infrastructure.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I also wrote and added the following tools to the toolset to fulfill the requirements of a fully automated deployment infrastructure:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/shuaibiyy/lambda-registry&#34;&gt;Lambda-Registry&lt;/a&gt; for managing HAProxy configurations.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/shuaibiyy/cosmonaut&#34;&gt;Cosmonaut&lt;/a&gt; for reloading HAProxy when container lifecycle events occur.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;terminologies:590f6df10d6bcf152493e39f0a6f759c&#34;&gt;Terminologies&lt;/h2&gt;

&lt;p&gt;A couple of terms and their meanings as understood by Lambda-Registry and Cosmonaut.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Service: A service is a name given to containers that serve the same purpose. Containers are grouped as a service using an environment variable.&lt;/li&gt;
&lt;li&gt;A container is a docker container, and an instance of a service is a single container.&lt;/li&gt;
&lt;li&gt;HAProxy config is a HAProxy configuration file, typically found in a file named &lt;code&gt;haproxy.cfg&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;lambda-registry-https-github-com-shuaibiyy-lambda-registry:590f6df10d6bcf152493e39f0a6f759c&#34;&gt;&lt;a href=&#34;https://github.com/shuaibiyy/lambda-registry&#34;&gt;Lambda-Registry&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Lambda-Registry is a tool for managing and generating HAProxy configurations for hosts running services in containers behind a HAProxy. Lambda-Registry receives a payload describing the state of services and returns a HAProxy config that matches that state. It also stores the data of past services, so their configurations persist across future HAProxy configs as long as there are running instances, i.e. containers, of them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sample request to Cosmonaut:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;table&amp;quot;: &amp;quot;astro&amp;quot;,
  &amp;quot;running&amp;quot;: [{
      &amp;quot;serviceName&amp;quot;: &amp;quot;app1&amp;quot;,
      &amp;quot;id&amp;quot;: &amp;quot;a23nj53h3j4&amp;quot;,
      &amp;quot;ip&amp;quot;: &amp;quot;192.168.1.9:80&amp;quot;
    },
    {
      &amp;quot;serviceName&amp;quot;: &amp;quot;app1&amp;quot;,
      &amp;quot;id&amp;quot;: &amp;quot;jk3243j54jl&amp;quot;,
      &amp;quot;ip&amp;quot;: &amp;quot;192.168.1.8:80&amp;quot;
    }
  ],
  &amp;quot;candidates&amp;quot;: [{
      &amp;quot;serviceName&amp;quot;: &amp;quot;app1&amp;quot;,
      &amp;quot;configMode&amp;quot;: &amp;quot;host&amp;quot;,
      &amp;quot;predicate&amp;quot;: &amp;quot;first.example.com&amp;quot;,
      &amp;quot;cookie&amp;quot;: &amp;quot;JSESSIONID&amp;quot;,
      &amp;quot;containers&amp;quot;: [{
          &amp;quot;id&amp;quot;: &amp;quot;a23nj53h3j4&amp;quot;,
          &amp;quot;ip&amp;quot;: &amp;quot;192.168.1.9:80&amp;quot;
        }
      ]
    },
    {
      &amp;quot;serviceName&amp;quot;: &amp;quot;app2&amp;quot;,
      &amp;quot;configMode&amp;quot;: &amp;quot;host&amp;quot;,
      &amp;quot;predicate&amp;quot;: &amp;quot;second.example.com&amp;quot;,
      &amp;quot;cookie&amp;quot;: &amp;quot;JSESSIONID&amp;quot;,
      &amp;quot;containers&amp;quot;: [{
          &amp;quot;id&amp;quot;: &amp;quot;das843j3h3k&amp;quot;,
          &amp;quot;ip&amp;quot;: &amp;quot;192.168.1.10:80&amp;quot;
        },
        {
          &amp;quot;id&amp;quot;: &amp;quot;fds32k4354f&amp;quot;,
          &amp;quot;ip&amp;quot;: &amp;quot;192.168.1.11:80&amp;quot;
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Explanation:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;table&lt;/strong&gt;: name of DynamoDB table where configurations will be stored.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;running&lt;/strong&gt;: instances of services running within the weave network.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;candidates&lt;/strong&gt;:  instances that are new to the weave network and do not yet exist in the HAProxy config.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;configMode&lt;/strong&gt;: type of routing. It can be either &lt;code&gt;Path&lt;/code&gt; or &lt;code&gt;Host&lt;/code&gt;. In &lt;code&gt;Path&lt;/code&gt; mode, the URL path is used to determine which backend to forward the request to. In &lt;code&gt;Host&lt;/code&gt; mode, the HTTP host header is used to determine which backend to forward the request to.
&lt;em&gt;Defaults to &lt;code&gt;host&lt;/code&gt; mode.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;serviceName&lt;/strong&gt;: name of service the containers belong to.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;predicate&lt;/strong&gt;: value used along with mode to determine which service a request will be forwarded to.
In &lt;code&gt;Path&lt;/code&gt; mode, the predicate looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    acl &amp;lt;cluster&amp;gt; url_beg /&amp;lt;predicate&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In &lt;code&gt;Host&lt;/code&gt; mode:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    acl &amp;lt;cluster&amp;gt; hdr(host) -i &amp;lt;predicate&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;cookie&lt;/strong&gt;: name of cookie to be used for sticky sessions. If not defined, sticky sessions will not be configured.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;containers&lt;/strong&gt;: key-value pairs of container ids and their corresponding IP addresses.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;HAProxy config generated from request:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;global
   log 127.0.0.1   local0
   log 127.0.0.1   local1 notice
   maxconn 4096
   user haproxy
   group haproxy
   daemon

defaults
    log global
    mode http
    option httplog
    option dontlognull
    option forwardfor
    option http-server-close
    timeout connect 5000
    timeout client 50000
    timeout server 50000

# Define frontends

frontend http
    bind :80

    acl app1 hdr(host) -i first.example.com
    use_backend app1 if app1

    acl app2 hdr(host) -i second.example.com
    use_backend app2 if app2


# Define backends

backend app1
    mode http
    balance roundrobin
    option forwardfor
    cookie JSESSIONID prefix nocache

    server a23nj53h3j4 192.168.1.9:80 check cookie JSESSIONID

backend app2
    mode http
    balance roundrobin
    option forwardfor
    cookie JSESSIONID prefix nocache

    server das843j3h3k 192.168.1.10:80 check cookie JSESSIONID

    server fds32k4354f 192.168.1.11:80 check cookie JSESSIONID
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cosmonaut-https-github-com-shuaibiyy-cosmonaut:590f6df10d6bcf152493e39f0a6f759c&#34;&gt;&lt;a href=&#34;https://github.com/shuaibiyy/cosmonaut&#34;&gt;Cosmonaut&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Cosmonaut is a tool for monitoring docker hosts and reloading their HAProxy configurations. When a docker event relevant to Cosmonaut occurs, it gathers information about the event and current state of services running on the host, and sends that information in a request to Lambda-Registry, which then returns a HAProxy config. Cosmonaut finally reloads the host&amp;rsquo;s HAProxy with the config it received. Currently, Cosmonaut expects HAProxy to be running in a &lt;a href=&#34;https://github.com/rstiller/dockerfiles/tree/master/haproxy&#34;&gt;container&lt;/a&gt;, and it updates it via a docker exec command.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On Immutable Infrastructure</title>
      <link>https://shuaib.me/immutable-infrastructure/</link>
      <pubDate>Fri, 06 May 2016 19:44:10 +0800</pubDate>
      
      <guid>https://shuaib.me/immutable-infrastructure/</guid>
      <description>&lt;p&gt;I believe there&amp;rsquo;s little convincing to be done on the merits of immutable deployment. With immutable deployment, the unit of abstraction is a machine image; a docker image, Amazon Machine Image (AMI), e.t.c. The idea is that your server, spawned from a machine image goes from being this special snowflake to [insert generic thing]. As opposed to meticulously maintaining a server and keeping track of its mutable configuration over time, you are able to provision it with a known configuration in a non-special way. Containerisation makes this easier because of the lightweight and wieldy characteristics of containers.&lt;/p&gt;

&lt;p&gt;Last week, I listened to a talk on &lt;strong&gt;immutable infrastructure&lt;/strong&gt;, titled &lt;a href=&#34;https://www.infoq.com/presentations/immutable-infrastructure&#34;&gt;Immutable Infrastructure: Rise of the Machine Images&lt;/a&gt;. The speaker expands on immutable deployment by talking about  how certain ancillary aspects of applications are affected by immutability, such as logging, sessions, configuration and service discovery. I highly recommend that talk as the speaker puts into words vaguely defined practices that have emerged from this growing trend.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Overcoming an AWS ECS Deficiency Using Terraform</title>
      <link>https://shuaib.me/overcoming-aws-ecs-deficiency-using-terraform/</link>
      <pubDate>Wed, 27 Apr 2016 05:58:17 +0800</pubDate>
      
      <guid>https://shuaib.me/overcoming-aws-ecs-deficiency-using-terraform/</guid>
      <description>&lt;p&gt;While trying to deploy an application using ECS, I hit into a popular deficiency, which is the inability to securely and dynamically supply values to environment variables defined in ECS task definitions. Docker serves that need by providing an &amp;ndash;env-file option for its run command. For ECS however, there are outstanding feature requests that have been raised on Github &lt;a href=&#34;https://github.com/aws/amazon-ecs-agent/issues/3&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://github.com/aws/amazon-ecs-agent/issues/247&#34;&gt;here&lt;/a&gt;. The ECS scheduler being a closed-source system means there&amp;rsquo;s no community to pick up backlog items that AWS engineers may never get around to.&lt;/p&gt;

&lt;p&gt;In this particular case, I was lucky enough to already be using &lt;a href=&#34;https://www.terraform.io/&#34;&gt;Terraform&lt;/a&gt; to provision my infrastructure, which made for an easy solution. For those unfamiliar with Terraform, it&amp;rsquo;s a tool from HashiCorp, the creators of Vagrant, that lets you write configurations in a language called HCL, which you can then run to provision resources on any supported cloud provider. Terraform codifies infrastructure, enabling what is known as Infrastructure as Code.&lt;/p&gt;

&lt;p&gt;Without further ado, I have a task definition called jenkins.json that initially contained this segment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;jenkins-backup&amp;quot;,
  &amp;quot;image&amp;quot;: &amp;quot;istepanov/backup-to-s3&amp;quot;,
  &amp;quot;memory&amp;quot;: 128,
  &amp;quot;cpu&amp;quot;: 10,
  &amp;quot;essential&amp;quot;: false,
  &amp;quot;environment&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;ACCESS_KEY&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;very_bad_practice&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;SECRET_KEY&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;dont_do_this&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;S3_PATH&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;s3://allhardcode/d/&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;CRON_SCHEDULE&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;0 12 * * *&amp;quot;
    }
  ],
  &amp;quot;mountPoints&amp;quot;: [
    {
      &amp;quot;sourceVolume&amp;quot;: &amp;quot;jenkins-home&amp;quot;,
      &amp;quot;containerPath&amp;quot;: &amp;quot;/data&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Clearly, the issue with the task definition above is that it is exposing credentials, and forcing you to hardcode values that you might want to set dynamically. The solution is to use &lt;a href=&#34;https://www.terraform.io/docs/providers/template/r/file.html&#34;&gt;&lt;strong&gt;Terraform&amp;rsquo;s template_file&lt;/strong&gt;&lt;/a&gt;. We can do that by creating a file called jenkins.json.tpl (the .tpl extension is not required), and it&amp;rsquo;ll contain this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;name&amp;quot;: &amp;quot;jenkins-backup&amp;quot;,
  &amp;quot;image&amp;quot;: &amp;quot;istepanov/backup-to-s3&amp;quot;,
  &amp;quot;memory&amp;quot;: 128,
  &amp;quot;cpu&amp;quot;: 10,
  &amp;quot;essential&amp;quot;: false,
  &amp;quot;environment&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;ACCESS_KEY&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;${aws_access_key}&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;SECRET_KEY&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;${aws_secret_key}&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;S3_PATH&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;s3://${s3_bucket}/${s3_path}/&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;CRON_SCHEDULE&amp;quot;,
      &amp;quot;value&amp;quot;: &amp;quot;0 12 * * *&amp;quot;
    }
  ],
  &amp;quot;mountPoints&amp;quot;: [
    {
      &amp;quot;sourceVolume&amp;quot;: &amp;quot;jenkins-home&amp;quot;,
      &amp;quot;containerPath&amp;quot;: &amp;quot;/data&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In our Terraform scripts, we declare the template file as a resource:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;template_file&amp;quot; &amp;quot;jenkins_task_template&amp;quot; {
  template = &amp;quot;${file(&amp;quot;jenkins.json.tpl&amp;quot;)}&amp;quot;

  vars {
    aws_access_key = &amp;quot;${var.aws_access_key}&amp;quot;
    aws_secret_key = &amp;quot;${var.aws_secret_key}&amp;quot;
    s3_bucket = &amp;quot;${var.s3_bucket}&amp;quot;
    s3_path = &amp;quot;${var.s3_path}&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The variable names in the vars section of the template_file definition match the placeholders in jenkins.json.tpl, and their values will be interpolated in the rendered template when it is used by a service like this one:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resource &amp;quot;aws_ecs_task_definition&amp;quot; &amp;quot;jenkins&amp;quot; {
  family = &amp;quot;jenkins&amp;quot;
  container_definitions = &amp;quot;${template_file.jenkins_task_template.rendered}&amp;quot;

  volume {
    name = &amp;quot;jenkins-home&amp;quot;
    host_path = &amp;quot;/ecs/jenkins-home&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Terraform provides all the means for &lt;a href=&#34;https://www.terraform.io/docs/configuration/variables.html&#34;&gt;specifying variables&lt;/a&gt; that one could ask for, and you can take advantage of them in your ECS task definitions and potentially lots of static configuration files out there. Sounds like a pretty sweet deal to me.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker Toolbox Upgrade Guide</title>
      <link>https://shuaib.me/docker-toolbox-upgrade-guide/</link>
      <pubDate>Mon, 25 Apr 2016 17:55:00 +0800</pubDate>
      
      <guid>https://shuaib.me/docker-toolbox-upgrade-guide/</guid>
      <description>&lt;ol&gt;
&lt;li&gt;Get the latest docker toolbox installer from the &lt;a href=&#34;https://www.docker.com/products/docker-toolbox&#34;&gt;docker website&lt;/a&gt;.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Stop all running docker machines, e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine stop dev
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Run the toolbox installer and agree to any upgrade request.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Once the installation is complete, you&amp;rsquo;ll need to upgrade the docker machine, e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine upgrade dev
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Start the docker machine e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine start dev
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If the docker machine&amp;rsquo;s IP changes, you&amp;rsquo;ll need to regenerate its certs, e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine regenerate-certs dev
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Configure your shell to use the docker machine as your docker engine, e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval &amp;quot;$(docker-machine env dev)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That&amp;rsquo;s it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On AWS Lambda, API Gateway and Terraform</title>
      <link>https://shuaib.me/aws-lambda-api-gateway-terraform/</link>
      <pubDate>Mon, 18 Apr 2016 12:50:49 +0800</pubDate>
      
      <guid>https://shuaib.me/aws-lambda-api-gateway-terraform/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/lambda/&#34;&gt;AWS Lambda&lt;/a&gt; is arguably the most exciting service released in AWS since EC2. Lambda is a service that lets you run code on someone else&amp;rsquo;s machine, in this case EC2. All you need to do is pick the runtime your code can run in, and provide the code. Currently, the supported runtimes are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Node.js: v0.10.36, v4.3.2&lt;/li&gt;
&lt;li&gt;Java: Java 8&lt;/li&gt;
&lt;li&gt;Python: Python 2.7&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Developing applications using Lambda differs from the way we are typically used to, in terms of codebase management, tooling, frameworks, testing and deployment. On one hand, Lambda offers us the entire AWS ecosystem with simple configurations, and on the other, it requires us to rethink how we approach building even small applications. There aren&amp;rsquo;t yet enough success stories and best practices out there to give one the confidence to build large applications using Lambda, but there&amp;rsquo;s enough information to start farming out computation heavy processes to Lambda. Lambda especially shines because of its ability to scale along with its workload.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/api-gateway/&#34;&gt;API Gateway&lt;/a&gt; is another exciting service on AWS that aims to ease the task of creating APIs. You define your resources and their models, request transformations, locations where requests should be proxied to, response transformations; and you get a functioning API without deploying a single machine. An API Gateway endpoint can use a Lambda function as its backend, which is the sweet spot touted by serverless architecture advocates.&lt;/p&gt;

&lt;p&gt;I recently created a small project using Lambda and API Gateway. When deployed, the application provides an API endpoint that can be used to generate a &lt;code&gt;haproxy.cfg&lt;/code&gt; file based on parameters provided. You can find the project source &lt;a href=&#34;https://github.com/shuaibiyy/haproxy-config-generator&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One major pain point of using Lambda and API Gateway is the difficulty of setting things up, so the project uses &lt;a href=&#34;https://terraform.io&#34;&gt;Terraform&lt;/a&gt; to ease that difficulty. Terraform is a tool that lets you define configurations, which it can run to provision resources on datacenters by providers such as AWS, Azure and Google Cloud. In this project, Terraform is used to provision the Lambda function and API Gateway resources. With Terraform installed, the project can be deployed by simply invoking:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;terraform apply
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and torn down using:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;terraform destroy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Like every system in its early life, API Gateway and Lambda have minor bugs and areas of improvement. One particular bug I couldn&amp;rsquo;t find a sensible workaround for is API Gateway failing to have the right permissions to talk with Lambda after deployment. The solution is to perform a ceremony described in &lt;a href=&#34;https://www.youtube.com/watch?v=H4LM_jw5zzs&#34;&gt;this youtube video&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Overall, the combination of these technologies is lethal, and I&amp;rsquo;m interested in seeing how functionality in existing applications can be chipped away to harness the strengths of these so-called serverless architectures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An SSL Termination Issue in Stormpath</title>
      <link>https://shuaib.me/stormpath-ssl-termination/</link>
      <pubDate>Wed, 13 Apr 2016 14:57:45 +0800</pubDate>
      
      <guid>https://shuaib.me/stormpath-ssl-termination/</guid>
      <description>&lt;p&gt;Our application sits behind Amazon&amp;rsquo;s Elastic Load Balancer (ELB), which is a convenient place for terminating SSL connections. We use the Stormpath servlet plugin and its token authentication feature for our Stormpath integration. For some reason though, requests from users trying to authenticate with our application errored out with the following message:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[http-listener-1(3)] DEBUG c.s.s.s.mvc.AccessTokenController - OAuth Access Token request failed.
com.stormpath.sdk.servlet.filter.oauth.OauthException: A secure HTTPS connection is required for token requests - this is a requirement of the OAuth 2 specification.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A look at the request headers from clients showed that &lt;code&gt;X-Forwarded-Proto&lt;/code&gt; headers were getting set. The &lt;code&gt;X-Forwarded-Proto&lt;/code&gt; header is responsible for informing the server of the protocol at the origin where a request was initiated. In our case, we wanted Glassfish to treat connections that had &lt;code&gt;X-Forwarded-Proto&lt;/code&gt; header values of &lt;code&gt;https&lt;/code&gt; as secured, so we configured it to do so. That however, still didn&amp;rsquo;t solve the problem.&lt;/p&gt;

&lt;p&gt;After some time spent in frustration and consideration of Stormpath alternatives, I found this &lt;a href=&#34;https://github.com/stormpath/stormpath-sdk-java/issues/139&#34;&gt;Github issue&lt;/a&gt;, which led to the following workaround:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Create this Factory:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SecureResolverFactory extends ConfigSingletonFactory&amp;lt;Resolver&amp;lt;Boolean&amp;gt;&amp;gt; {


    public static final String LOCALHOST_RESOLVER = &amp;quot;stormpath.web.localhost.resolver&amp;quot;;


    @Override
    protected Resolver&amp;lt;Boolean&amp;gt; createInstance(ServletContext servletContext) throws Exception {
        return new SecureForwardedProtoAwareResolver(new IsHTTPSForwardedProtoResolver(), new SecureRequiredExceptForLocalhostResolver(getConfig().getInstance(LOCALHOST_RESOLVER)));
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In stormpath.properties add:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;stormpath.web.accessToken.authorizer.secure.resolver = com.mycompany.resolver.SecureResolverFactory
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create these Resolvers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class IsHTTPSForwardedProtoResolver implements Resolver&amp;lt;Boolean&amp;gt; {


    private static final String HEADER_FORWARDED_PROTO = &amp;quot;X-Forwarded-Proto&amp;quot;;


    @Override
    public Boolean get(HttpServletRequest request, HttpServletResponse response) {
        String protocol = request.getHeader(HEADER_FORWARDED_PROTO);
        if (protocol != null &amp;amp;&amp;amp; protocol.equalsIgnoreCase(&amp;quot;https&amp;quot;)) {
            return true;
        }
        return false;
    }
}


public class SecureForwardedProtoAwareResolver implements Resolver&amp;lt;Boolean&amp;gt; {


    private final Resolver&amp;lt;Boolean&amp;gt; isHTTPSForwardedProtoResolver;
    private final Resolver&amp;lt;Boolean&amp;gt; secureRequiredExceptForLocalhostResolver;


    public SecureForwardedProtoAwareResolver(Resolver&amp;lt;Boolean&amp;gt; isHTTPSForwardedProtoResolver, Resolver&amp;lt;Boolean&amp;gt; secureRequiredExceptForLocalhostResolver) {
        Assert.notNull(isHTTPSForwardedProtoResolver, &amp;quot;isHTTPSForwardedProtoResolver resolver cannot be null.&amp;quot;);
        Assert.notNull(secureRequiredExceptForLocalhostResolver, &amp;quot;secureRequiredExceptForLocalhost resolver cannot be null.&amp;quot;);
        this.isHTTPSForwardedProtoResolver = isHTTPSForwardedProtoResolver;
        this.secureRequiredExceptForLocalhostResolver = secureRequiredExceptForLocalhostResolver;
    }


    @Override
    public Boolean get(HttpServletRequest request, HttpServletResponse response) {
        if (this.isHTTPSForwardedProtoResolver.get(request, response)) {
            return false;
        }
        return this.secureRequiredExceptForLocalhostResolver.get(request, response);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s it, Stormpath now considers requests with &lt;code&gt;X-Forwarded-Proto&lt;/code&gt;  values of &lt;code&gt;https&lt;/code&gt; as secured.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>On Weave</title>
      <link>https://shuaib.me/on-weave/</link>
      <pubDate>Thu, 07 Apr 2016 23:39:40 +0800</pubDate>
      
      <guid>https://shuaib.me/on-weave/</guid>
      <description>&lt;p&gt;I have been looking for a simple (as in &lt;a href=&#34;https://en.wikipedia.org/wiki/Bus_factor&#34;&gt;bus factor&lt;/a&gt; of 0) deployment solution for single-tenanted and microservice applications for a while now, which sort of rules out tonnes of sophisticated tools out there. I read this blog post a couple of days ago: &lt;a href=&#34;https://www.weave.works/guides/service-discovery-and-load-balancing-with-weave-on-amazon-ecs-2/&#34;&gt;The fastest path to Docker on ECS: microservice deployment on Amazon EC2 Container Service with Weave Net&lt;/a&gt;.  I was really impressed with the simplicity of Weave, so I decided to port the setup to a Terraform module because Infrastructure-as-code is &lt;strong&gt;it&lt;/strong&gt;,  and I plan to improve on it for a deployment solution I&amp;rsquo;m working on. You can find the Terraform module &lt;a href=&#34;https://github.com/shuaibiyy/ecs-weave-terraform-microservice-demo&#34;&gt;in this github repo&lt;/a&gt;. I think I&amp;rsquo;ve found a usable arsenal of deployment tools that work well together, and it includes Weave.  I plan on writing about my solution once it works out there.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ongoing Clojure Journey</title>
      <link>https://shuaib.me/clojure-journey/</link>
      <pubDate>Wed, 06 Apr 2016 15:35:23 +0800</pubDate>
      
      <guid>https://shuaib.me/clojure-journey/</guid>
      <description>&lt;p&gt;This a live post that I&amp;rsquo;ll update as I continue to explore Clojure. The materials are listed in chronological order. I guess it&amp;rsquo;s evident I prefer taking in a lot of audio-visual content when learning new topics.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Listened to a lot of &lt;a href=&#34;https://www.functionalgeekery.com/&#34;&gt;Functional Geekery&lt;/a&gt; and &lt;a href=&#34;http://blog.cognitect.com/cognicast/&#34;&gt;Cognicast&lt;/a&gt; podcasts for the first couple of months, which is how I got into Clojure.&lt;/li&gt;
&lt;li&gt;Watched the &lt;a href=&#34;http://www.lynda.com/Clojure-tutorials/Up-Running-Clojure/413127-2.html&#34;&gt;Up and Running with Clojure&lt;/a&gt; tutorial on Lynda.&lt;/li&gt;
&lt;li&gt;Watched Chas Emerick’s video on &lt;a href=&#34;http://cemerick.com/2012/05/02/starting-clojure/&#34;&gt;Starting Clojure&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Watched Expert to Expert: Rich Hickey and Brian Beckman - &lt;a href=&#34;https://www.youtube.com/watch?v=wASCH_gPnDw&#34;&gt;Inside Clojure&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Watched Rich Hickey’s talk: &lt;a href=&#34;https://www.youtube.com/watch?v=VSdnJDO-xdg&#34;&gt;Clojure, Made Simple&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Watched &lt;a href=&#34;http://www.clojurescreencasts.com/koans-walkthrough/01.html&#34;&gt;Clojure Koans Walkthrough&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Currently reading &lt;a href=&#34;https://pragprog.com/book/shcloj2/programming-clojure&#34;&gt;Programming Clojure&lt;/a&gt; by Stuart Halloway and Aaron Bedra.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>